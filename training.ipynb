{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":514245,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":406541,"modelId":424454}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ======================\n# 1. SETUP ENVIRONMENT\n# ======================\nimport os\nimport re\nimport requests\nimport zipfile\nimport json\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport pandas as pd\nimport time\n\n# Setup directories\n!rm -rf /kaggle/working/*\n!mkdir -p /kaggle/working/{data,cleaned_scripts,logs}\n           \n!mkdir -p /kaggle/working/data/{raw,preprocessed}/{cornell,imsdb,springfield,screenplaydb}\n\n# ======================\n# 2. DOWNLOAD ALL DATASETS\n# ======================\ndef download_cornell():\n    cornell_url = \"https://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\"\n    cornell_zip = \"/kaggle/working/data/raw/cornell.zip\"\n\n    print(\"‚¨áÔ∏è Downloading Cornell dataset...\")\n    response = requests.get(cornell_url, stream=True)\n    response.raise_for_status()\n\n    with open(cornell_zip, 'wb') as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n    # Verify download\n    if os.path.exists(cornell_zip):\n        print(f\"‚úÖ Downloaded: {os.path.getsize(cornell_zip)/1024/1024:.2f} MB\")\n    else:\n        raise Exception(\"Download failed!\")\n\n    # Extract\n    print(\"üìÇ Extracting...\")\n    with zipfile.ZipFile(cornell_zip, 'r') as z:\n        z.extractall(\"/kaggle/working/data/raw/cornell\")\n\ndef download_imsdb_script(movie):\n    try:\n        url = f\"https://imsdb.com/scripts/{movie}.html\"\n        response = requests.get(url, timeout=10)\n        if response.status_code == 200:\n            text = re.search(r'<pre>(.*?)</pre>', response.text, re.DOTALL)\n            if text:\n                clean_text = re.sub(r'<.*?>', '', text.group(1))\n                with open(f\"/kaggle/working/data/raw/imsdb/{movie}.txt\", 'w') as f:\n                    f.write(clean_text)\n                return True\n    except Exception as e:\n        print(f\"‚ö†Ô∏è {movie}: {str(e)}\")\n    return False\n\ndef download_springfield_script(movie):\n    try:\n        url = f\"https://www.springfieldspringfield.co.uk/movie_script.php?movie={movie}\"\n        response = requests.get(url, timeout=10)\n        if response.status_code == 200:\n            text = re.search(r'<div class=\"scrolling-script-container\">(.*?)</div>', response.text, re.DOTALL)\n            if text:\n                clean_text = re.sub(r'<.*?>', '', text.group(1))\n                clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n                with open(f\"/kaggle/working/data/raw/springfield/{movie}.txt\", 'w') as f:\n                    f.write(clean_text)\n                return True\n    except Exception as e:\n        print(f\"‚ö†Ô∏è {movie}: {str(e)}\")\n    return False\n\ndef download_screenplaydb_script(movie, url):\n    try:\n        response = requests.get(url, timeout=10)\n        if response.status_code == 200:\n            with open(f\"/kaggle/working/data/raw/screenplaydb/{movie}.txt\", 'w') as f:\n                f.write(response.text)\n            return True\n    except Exception as e:\n        print(f\"‚ö†Ô∏è {movie}: {str(e)}\")\n    return False\n\n# Download all datasets\nprint(\"Starting dataset downloads...\")\ndownload_cornell()\n\n# IMSDb scripts\nimsdb_movies = [\n    'Pulp-Fiction', 'The-Matrix', 'Inception',\n    'The-Dark-Knight', 'Fight-Club', 'Forrest-Gump',\n    'Good-Will-Hunting', 'The-Shawshank-Redemption',\n    'The-Godfather', 'The-Social-Network',\n    'Interstellar', 'The-Prestige', 'Se7en',\n    'The-Truman-Show', 'American-Beauty']\nfor movie in tqdm(imsdb_movies, desc=\"Downloading IMSDb\"):\n    download_imsdb_script(movie)\n\n# Springfield scripts\nspringfield_movies = [\n    'alien', 'blade-runner', 'casablanca',\n    'citizen-kane', 'gravity', 'her',\n    'jurassic-park', 'la-la-land', 'mad-max-fury-road',\n    'the-martian', 'psycho', 'the-shining',\n    'eternal-sunshine-of-the-spotless-mind', 'the-grand-budapest-hotel',\n    'moonlight', 'parasite', 'whiplash'\n]\n\nfor movie in tqdm(springfield_movies, desc=\"Downloading Springfield\"):\n    download_springfield_script(movie)\n\n\n# ScreenplayDB scripts\nscreenplaydb_movies = {\n    '12-angry-men': 'https://www.screenplaydb.com/film/scripts/12-angry-men.txt',\n    'birdman': 'https://www.screenplaydb.com/film/scripts/birdman.txt'\n}\nfor movie, url in tqdm(screenplaydb_movies.items(), desc=\"Downloading ScreenplayDB\"):\n    download_screenplaydb_script(movie, url)\n\n# ======================\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:43:28.236624Z","iopub.execute_input":"2025-08-08T07:43:28.236859Z","iopub.status.idle":"2025-08-08T07:43:45.983107Z","shell.execute_reply.started":"2025-08-08T07:43:28.236836Z","shell.execute_reply":"2025-08-08T07:43:45.982334Z"}},"outputs":[{"name":"stdout","text":"Starting dataset downloads...\n‚¨áÔ∏è Downloading Cornell dataset...\n‚úÖ Downloaded: 9.46 MB\nüìÇ Extracting...\n","output_type":"stream"},{"name":"stderr","text":"Downloading IMSDb: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:03<00:00,  4.82it/s]\nDownloading Springfield: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:12<00:00,  1.41it/s]\nDownloading ScreenplayDB:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  4.44it/s]","output_type":"stream"},{"name":"stdout","text":"‚ö†Ô∏è 12-angry-men: HTTPSConnectionPool(host='www.screenplaydb.com', port=443): Max retries exceeded with url: /film/scripts/12-angry-men.txt (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1016)')))\n","output_type":"stream"},{"name":"stderr","text":"Downloading ScreenplayDB: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  3.91it/s]","output_type":"stream"},{"name":"stdout","text":"‚ö†Ô∏è birdman: HTTPSConnectionPool(host='www.screenplaydb.com', port=443): Max retries exceeded with url: /film/scripts/birdman.txt (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1016)')))\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ======================\n# 3. VERIFY DOWNLOADS\n# ======================\ndef count_files(directory, extension=\"*.txt\"):\n    return len(list(Path(directory).rglob(extension)))\n\ndef verify_downloads():\n    print(\"\\nüîç DOWNLOAD VERIFICATION:\")\n    \n    print(\"\\nüìÇ Cornell:\")\n    cornell_files = count_files(\"/kaggle/working/data/raw/cornell\")\n    print(f\"{cornell_files} files\")\n    \n    print(\"\\nüìÇ IMSDb:\")\n    imsdb_files = count_files(\"/kaggle/working/data/raw/imsdb\")\n    print(f\"{imsdb_files} scripts\")\n    \n    print(\"\\nüìÇ Springfield:\")\n    springfield_files = count_files(\"/kaggle/working/data/raw/springfield\")\n    print(f\"{springfield_files} scripts\")\n    \n    print(\"\\nüìÇ ScreenplayDB:\")\n    screenplaydb_files = count_files(\"/kaggle/working/data/raw/screenplaydb\")\n    print(f\"{screenplaydb_files} scripts\")\n\nverify_downloads()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:43:45.987143Z","iopub.execute_input":"2025-08-08T07:43:45.987426Z","iopub.status.idle":"2025-08-08T07:43:45.994569Z","shell.execute_reply.started":"2025-08-08T07:43:45.987391Z","shell.execute_reply":"2025-08-08T07:43:45.993896Z"}},"outputs":[{"name":"stdout","text":"\nüîç DOWNLOAD VERIFICATION:\n\nüìÇ Cornell:\n7 files\n\nüìÇ IMSDb:\n15 scripts\n\nüìÇ Springfield:\n17 scripts\n\nüìÇ ScreenplayDB:\n0 scripts\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ======================\n# 4. PROCESS CORNELL DATA\n# ======================\ndef clean_cornell(input_path, output_path):\n    with open(input_path, 'r', encoding='latin-1', errors='ignore') as f:\n        lines = f.readlines()\n    \n    cleaned = []\n    for line in lines:\n        if line.count('+++$+++') < 4:\n            continue\n            \n        parts = line.split(' +++$+++ ')\n        if len(parts) < 5:\n            continue\n            \n        character = parts[3].strip().upper()\n        dialogue = parts[4].strip()\n        \n        if character and dialogue:\n            cleaned.append(f\"{character}: {dialogue}\")\n    \n    with open(output_path, 'w') as f:\n        f.write(\"\\n\".join(cleaned))\n    print(f\"‚úÖ Saved {len(cleaned)} dialogues to {output_path}\")\n\ncornell_input = \"/kaggle/working/data/raw/cornell/cornell movie-dialogs corpus/movie_lines.txt\"\ncornell_output = \"/kaggle/working/cleaned_scripts/cornell_dialogues.txt\"\nclean_cornell(cornell_input, cornell_output)\n\n# Verify Cornell output\nprint(\"\\nüîç First 5 Cornell dialogues:\")\n!head -n 5 {cornell_output}\nprint(f\"\\nüìú Total lines: {sum(1 for _ in open(cornell_output))}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:43:45.995458Z","iopub.execute_input":"2025-08-08T07:43:45.995670Z","iopub.status.idle":"2025-08-08T07:43:46.618076Z","shell.execute_reply.started":"2025-08-08T07:43:45.995653Z","shell.execute_reply":"2025-08-08T07:43:46.617358Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Saved 304403 dialogues to /kaggle/working/cleaned_scripts/cornell_dialogues.txt\n\nüîç First 5 Cornell dialogues:\nBIANCA: They do not!\nCAMERON: They do to!\nBIANCA: I hope so.\nCAMERON: She okay?\nBIANCA: Let's go.\n\nüìú Total lines: 304403\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ======================\n# 5. PROCESS SCREENPLAYS\n# ======================\ndef clean_screenplay(text):\n    text = re.sub(r'<.*?>|http\\S+|\\(.*?\\)|\\*.*?\\*|\\[.*?\\]', '', text)\n    text = re.sub(r'^.*?(INT\\.|EXT\\.|FADE IN:)', r'\\1', text, flags=re.DOTALL|re.IGNORECASE)\n    text = re.sub(r'(CUT TO:|DISSOLVE TO:|FADE OUT\\.).*?\\n', '', text)\n    text = re.sub(r'^\\s*([A-Z][A-Z\\s]+)\\s*$', r'\\1:', text, flags=re.MULTILINE)\n    text = re.sub(r'[^\\w\\s.,!?\\':-]', '', text)\n    return re.sub(r'\\s+', ' ', text).strip()\n\ndef process_all_files():\n    \"\"\"Process all datasets including Cornell movie dialogues\"\"\"\n    # First process Cornell dataset (special handling)\n    print(\"\\nüîÑ Processing Cornell movie dialogues...\")\n    cornell_input = \"/kaggle/working/data/raw/cornell/cornell movie-dialogs corpus/movie_lines.txt\"\n    cornell_output = \"/kaggle/working/data/preprocessed/cornell/cornell_dialogues.txt\"\n    \n    # Create output directory if it doesn't exist\n    Path(\"/kaggle/working/data/preprocessed/cornell\").mkdir(parents=True, exist_ok=True)\n    \n    clean_cornell(cornell_input, cornell_output)\n\n    # Then process screenplay datasets\n    sources = {\n        \"imsdb\": \"/kaggle/working/data/raw/imsdb\",\n        \"springfield\": \"/kaggle/working/data/raw/springfield\", \n        \"screenplaydb\": \"/kaggle/working/data/raw/screenplaydb\"\n    }\n    \n    for source, path in sources.items():\n        print(f\"\\nüîÑ Processing {source} scripts...\")\n        Path(f\"/kaggle/working/data/preprocessed/{source}\").mkdir(parents=True, exist_ok=True)\n        \n        for script in Path(path).glob(\"*.txt\"):\n            try:\n                with open(script, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                \n                cleaned = clean_screenplay(content)\n                \n                output_path = f\"/kaggle/working/data/preprocessed/{source}/{script.stem}_clean.txt\"\n                \n                with open(output_path, 'w') as f_out:\n                    f_out.write(cleaned)\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Error processing {script.name}: {str(e)}\")\n\n# And the corresponding verify_preprocessing function:\ndef verify_preprocessing():\n    print(\"\\nüîç PREPROCESSING VERIFICATION:\")\n    \n    # Verify Cornell processing\n    print(\"\\nüìÇ Cornell (Preprocessed):\")\n    cornell_files = list(Path(\"/kaggle/working/data/preprocessed/cornell\").glob(\"*.txt\"))\n    print(f\"{len(cornell_files)} files\")\n    if cornell_files:\n        with open(cornell_files[0], 'r') as f:\n            print(f\"Sample line: {f.readline().strip()}\")\n    \n    # Verify screenplays\n    print(\"\\nüìÇ IMSDb (Preprocessed):\")\n    imsdb_files = list(Path(\"/kaggle/working/data/preprocessed/imsdb\").glob(\"*_clean.txt\"))\n    print(f\"{len(imsdb_files)} scripts\")\n    \n    print(\"\\nüìÇ Springfield (Preprocessed):\")\n    springfield_files = list(Path(\"/kaggle/working/data/preprocessed/springfield\").glob(\"*_clean.txt\"))\n    print(f\"{len(springfield_files)} scripts\")\n    \n    print(\"\\nüìÇ ScreenplayDB (Preprocessed):\")\n    screenplaydb_files = list(Path(\"/kaggle/working/data/preprocessed/screenplaydb\").glob(\"*_clean.txt\"))\n    print(f\"{len(screenplaydb_files)} scripts\")\n\n# Run the processing\nprocess_all_files()\nverify_preprocessing()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:43:46.619367Z","iopub.execute_input":"2025-08-08T07:43:46.620034Z","iopub.status.idle":"2025-08-08T07:43:47.345059Z","shell.execute_reply.started":"2025-08-08T07:43:46.620002Z","shell.execute_reply":"2025-08-08T07:43:47.344520Z"}},"outputs":[{"name":"stdout","text":"\nüîÑ Processing Cornell movie dialogues...\n‚úÖ Saved 304403 dialogues to /kaggle/working/data/preprocessed/cornell/cornell_dialogues.txt\n\nüîÑ Processing imsdb scripts...\n\nüîÑ Processing springfield scripts...\n\nüîÑ Processing screenplaydb scripts...\n\nüîç PREPROCESSING VERIFICATION:\n\nüìÇ Cornell (Preprocessed):\n1 files\nSample line: BIANCA: They do not!\n\nüìÇ IMSDb (Preprocessed):\n15 scripts\n\nüìÇ Springfield (Preprocessed):\n17 scripts\n\nüìÇ ScreenplayDB (Preprocessed):\n0 scripts\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ======================\n# 1. AUTHENTICATION SETUP\n# ======================\nfrom huggingface_hub import login\nfrom transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\nimport torch\n\n# Login with your token\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:43:47.346791Z","iopub.execute_input":"2025-08-08T07:43:47.347432Z","iopub.status.idle":"2025-08-08T07:44:15.232908Z","shell.execute_reply.started":"2025-08-08T07:43:47.347403Z","shell.execute_reply":"2025-08-08T07:44:15.232313Z"}},"outputs":[{"name":"stderr","text":"2025-08-08 07:43:59.365484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754639039.609479      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754639039.681248      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 3. EMOTION CLASSIFICATION SETUP (FIXED)\n# ======================\n# 3. EMOTION CLASSIFICATION SETUP (FIXED PROPERLY)\n# ======================\ntry:\n    \n    # Load components separately with proper config\n    model_name = \"adcg1355/moodmatemodels\"\n    model_name = \"adcg1355/moodmatemodels\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, truncation_side='left')\n    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n    # Patch model.forward to remove token_type_ids\n    original_forward = model.forward\n    def patched_forward(*args, **kwargs):\n        kwargs.pop('token_type_ids', None)\n        return original_forward(*args, **kwargs)\n    model.forward = patched_forward\n\n    # Create pipeline\n    emotion_classifier = pipeline(\n        \"text-classification\",\n         model=model,\n         tokenizer=tokenizer,\n         framework=\"pt\",\n         device=0 if torch.cuda.is_available() else -1,\n         truncation=True,\n         max_length=512,\n    )\n    \n    \n    \n    # Load tokenizer with special settings\n    \n    \n    \n    \n    print(\"‚úÖ Emotion classifier loaded successfully (DistilBERT patched)\")\nexcept Exception as e:\n    print(f\"‚ùå Failed to load emotion classifier: {str(e)}\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:44:15.233598Z","iopub.execute_input":"2025-08-08T07:44:15.234043Z","iopub.status.idle":"2025-08-08T07:44:18.286234Z","shell.execute_reply.started":"2025-08-08T07:44:15.234022Z","shell.execute_reply":"2025-08-08T07:44:18.285620Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dcfee0ad7534535a1fd0a2bfa80a7a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4253138c70184ed1aba482faeac455ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6069e24e189f4be293e8ecb216a135e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6be8d5e0b71a48d594277cf573f7506a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e651dea75d7e459596613e35eb8fbf87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d601479794e400d856f11d5295139b0"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Emotion classifier loaded successfully (DistilBERT patched)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 4. EMOTION TAGGING FUNCTION\n# ======================\ndef get_emotion(dialogue):\n    \"\"\"Ultra-robust emotion classification\"\"\"\n    try:\n        # Clean input\n        clean_text = ''.join(char for char in dialogue[:500] if char.isprintable())\n        \n        # Optional sleep to avoid rate limits (if needed)\n        time.sleep(0.1)\n        \n        # Run emotion classifier\n        result = emotion_classifier(\n            clean_text,\n            truncation=True,\n            max_length=128,\n            padding='max_length'\n        )\n        \n        return result[0] if isinstance(result, list) else {'label': 'neutral', 'score': 0.0}\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Skipped line (error: {str(e)}): {dialogue[:50]}\")\n        return {'label': 'neutral', 'score': 0.0}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T07:44:18.286911Z","iopub.execute_input":"2025-08-08T07:44:18.287136Z","iopub.status.idle":"2025-08-08T07:44:18.292503Z","shell.execute_reply.started":"2025-08-08T07:44:18.287118Z","shell.execute_reply":"2025-08-08T07:44:18.291776Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nimport os\nfrom IPython.display import FileLink\nfrom tqdm.notebook import tqdm\nfrom transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import Dataset\nimport torch\n\n# ======================\n# 1. PATH CONFIGURATION & SETUP\n# ======================\n# Define all paths\nCLEANED_INPUT = \"/kaggle/working/cleaned_scripts/cornell_dialogues.txt\"\nENHANCED_OUTPUT = \"/kaggle/working/data/cleaned_cornell.txt\"\n\n# Create directories if they don't exist\nPath(CLEANED_INPUT).parent.mkdir(parents=True, exist_ok=True)\nPath(ENHANCED_OUTPUT).parent.mkdir(parents=True, exist_ok=True)\n\n# ======================\n# 2. SETUP THE EMOTION CLASSIFICATION PIPELINE (USING YOUR MODEL)\n# ======================\ntry:\n    # Load components separately with proper config\n    model_name = \"adcg1355/moodmatemodels\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, truncation_side='left')\n    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n    # Patch model.forward to remove token_type_ids\n    original_forward = model.forward\n    def patched_forward(*args, **kwargs):\n        kwargs.pop('token_type_ids', None)\n        return original_forward(*args, **kwargs)\n    model.forward = patched_forward\n\n    # Create pipeline\n    emotion_classifier = pipeline(\n        \"text-classification\",\n        model=model,\n        tokenizer=tokenizer,\n        framework=\"pt\",\n        device=0 if torch.cuda.is_available() else -1,\n        truncation=True,\n        max_length=512,\n    )\n    \n    print(\"‚úÖ Emotion classifier loaded successfully (DistilBERT patched)\")\nexcept Exception as e:\n    print(f\"‚ùå Failed to load emotion classifier: {str(e)}\")\n    raise\n\n# ======================\n# 3. ENHANCED PROCESSING (MODIFIED)\n# ======================\ndef enhance_with_emotion(input_path, output_path, batch_size=32):\n    \"\"\"\n    Processes dialogues with emotion tags using a batched approach for speed.\n    This function reads the entire file into a Dataset and then feeds it\n    to the Hugging Face pipeline in batches.\n    \"\"\"\n    # Create the correct mapping from numerical labels to emotion names from the GoEmotions dataset\n    # This list of 28 emotions is based on the default `id2label` mapping.\n    emotion_labels = [\n        'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n        'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n        'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n        'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n        'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n    ]\n    emotion_map = {f'LABEL_{i}': label for i, label in enumerate(emotion_labels)}\n\n    # Verify input exists\n    if not Path(input_path).exists():\n        print(f\"‚ùå Input file not found: {input_path}\")\n        return []\n\n    enhanced = []\n    dialogues_to_process = []\n    \n    # Read all dialogue lines from the input file first\n    with open(input_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            if \": \" in line:\n                dialogues_to_process.append(line.strip())\n\n    if not dialogues_to_process:\n        print(\"‚ùå No dialogues found in the input file to process.\")\n        return []\n\n    # Create a Hugging Face Dataset from our list of dialogues\n    dataset = Dataset.from_dict({'text': dialogues_to_process})\n\n    try:\n        # Pass the dataset and batch size to the pipeline.\n        all_results = emotion_classifier(dataset['text'], batch_size=batch_size)\n\n        # Now, combine the original dialogues with the new emotion data\n        for dialogue, result in tqdm(zip(dialogues_to_process, all_results), total=len(dialogues_to_process), desc=\"Finalizing\"):\n            try:\n                character, text = dialogue.split(\": \", 1)\n                # Use the mapping to get the real emotion name\n                emotion_label = result['label']\n                emotion = emotion_map.get(emotion_label, \"unknown\") # Use .get to avoid errors\n                score = result['score']\n\n                enhanced.append({\n                    \"text\": dialogue,\n                    \"metadata\": {\n                        \"character\": character,\n                        \"emotion\": emotion,\n                        \"score\": float(score),\n                        \"source\": \"cornell\"\n                    }\n                })\n            except Exception as e:\n                # Log occasional errors\n                if len(enhanced) % 1000 == 0:\n                    print(f\"‚ö†Ô∏è Skipped dialogue due to error: {str(e)[:50]}...\")\n                continue\n        \n        # Atomic write with verification\n        temp_path = f\"{output_path}.tmp\"\n        with open(temp_path, 'w', encoding='utf-8') as f:\n            json.dump(enhanced, f, indent=4)\n\n        # Verify temp file was created\n        if not Path(temp_path).exists():\n            raise Exception(\"Temporary file not created\")\n\n        # Atomic move\n        os.replace(temp_path, output_path)\n\n        # Final verification\n        if not Path(output_path).exists():\n            raise Exception(\"Final output file missing\")\n            \n        print(f\"\\n‚úÖ Successfully saved {len(enhanced)} dialogues to:\")\n        display(FileLink(output_path))\n            \n        return enhanced\n            \n    except Exception as e:\n        print(f\"‚ùå Critical error: {str(e)}\")\n        if 'temp_path' in locals() and Path(temp_path).exists():\n            os.remove(temp_path)\n        return []\n\n# ======================\n# 4. EXECUTION & VERIFICATION\n# ======================\n# Run the processing\nenhanced_data = enhance_with_emotion(\n    input_path=CLEANED_INPUT,\n    output_path=ENHANCED_OUTPUT\n)\n\n# Final verification\nif enhanced_data:\n    print(\"\\nüîç FINAL VERIFICATION\")\n    print(f\"Total dialogues processed: {len(enhanced_data)}\")\n    print(\"Sample metadata:\")\n    print(enhanced_data[0]['metadata'])\n    \n    # Force Kaggle to refresh\n    !ls -lh \"/kaggle/working/data/\"\nelse:\n    print(\"\\nüö® Processing failed - no output generated\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T08:27:48.082356Z","iopub.execute_input":"2025-08-08T08:27:48.083185Z","iopub.status.idle":"2025-08-08T08:39:59.170837Z","shell.execute_reply.started":"2025-08-08T08:27:48.083151Z","shell.execute_reply":"2025-08-08T08:39:59.169885Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Emotion classifier loaded successfully (DistilBERT patched)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Finalizing:   0%|          | 0/304403 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26dac2608c24a509e387714569023bf"}},"metadata":{}},{"name":"stdout","text":"\n‚úÖ Successfully saved 304403 dialogues to:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/data/cleaned_cornell.txt","text/html":"<a href='/kaggle/working/data/cleaned_cornell.txt' target='_blank'>/kaggle/working/data/cleaned_cornell.txt</a><br>"},"metadata":{}},{"name":"stdout","text":"\nüîç FINAL VERIFICATION\nTotal dialogues processed: 304403\nSample metadata:\n{'character': 'BIANCA', 'emotion': 'neutral', 'score': 0.7312625646591187, 'source': 'cornell'}\ntotal 79M\n-rw-r--r-- 1 root root  79M Aug  8 08:39 cleaned_cornell.txt\ndrwxr-xr-x 6 root root 4.0K Aug  8 07:43 preprocessed\ndrwxr-xr-x 6 root root 4.0K Aug  8 07:43 raw\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom IPython.display import FileLink\n\n# ======================\n# 1. PATH CONFIGURATION\n# ======================\n# --- Input Paths ---\n# This path is based on your emotion tagging script's output\nCORNELL_EMOTION_INPUT = \"/kaggle/working/data/cleaned_cornell.txt\"\n# This path is where your preprocessed screenplays should be\nSCREENPLAY_ROOT_DIR = \"/kaggle/working/data/preprocessed\"\n\n# --- Output Path ---\nFINAL_DATA_OUTPUT = \"/kaggle/working/data/final_dataset.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:01:58.490817Z","iopub.execute_input":"2025-08-08T09:01:58.491407Z","iopub.status.idle":"2025-08-08T09:01:58.495579Z","shell.execute_reply.started":"2025-08-08T09:01:58.491382Z","shell.execute_reply":"2025-08-08T09:01:58.494800Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# ======================\n# 2. SPECIAL TOKENS & METADATA\n# ======================\nSPECIAL_TOKENS = {\n    \"cornell\": \"<CORNELL_DIALOGUE>\",\n    \"screenplay\": \"<SCREENPLAY>\"\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:02:12.988446Z","iopub.execute_input":"2025-08-08T09:02:12.988904Z","iopub.status.idle":"2025-08-08T09:02:12.992439Z","shell.execute_reply.started":"2025-08-08T09:02:12.988880Z","shell.execute_reply":"2025-08-08T09:02:12.991681Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\n# ======================\n# 3. HELPER FUNCTIONS\n# ======================\ndef load_and_tag_cornell(input_path):\n    \"\"\"\n    Loads the emotion-tagged Cornell data and adds the special token\n    and 'type' metadata.\n    \"\"\"\n    if not Path(input_path).exists():\n        print(f\"‚ùå Cornell file not found: {input_path}\")\n        return []\n    \n    with open(input_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    # We're updating the existing data structure\n    for item in tqdm(data, desc=\"Tagging Cornell data\"):\n        item[\"text\"] = f\"{SPECIAL_TOKENS['cornell']} {item['text']}\"\n        item[\"metadata\"][\"type\"] = \"cornell\"\n    \n    return data\n\ndef load_and_tag_screenplays(root_dir):\n    \"\"\"\n    Loads all preprocessed screenplay files, combines them,\n    and adds the special token and type metadata.\n    \"\"\"\n    all_screenplays = []\n    \n    # The list of screenplay sources to process\n    sources = [\"imsdb\", \"springfield\", \"screenplaydb\"]\n    for source in sources:\n        source_path = Path(root_dir) / source\n        if not source_path.exists():\n            print(f\"‚ö†Ô∏è Directory not found for {source}. Skipping.\")\n            continue\n        \n        script_files = list(source_path.glob(\"*_clean.txt\"))\n        for script_file in tqdm(script_files, desc=f\"Tagging {source} scripts\"):\n            try:\n                with open(script_file, 'r', encoding='utf-8') as f:\n                    content = f.read().strip() # .strip() removes leading/trailing whitespace\n                \n                # IMPORTANT FIX: Check if content is not empty before processing\n                if not content:\n                    print(f\"‚ö†Ô∏è Skipping empty file: {script_file.name}\")\n                    continue\n                \n                tagged_text = f\"{SPECIAL_TOKENS['screenplay']} {content}\"\n                \n                all_screenplays.append({\n                    \"text\": tagged_text,\n                    \"metadata\": {\n                        \"type\": \"screenplay\",\n                        \"source\": source,\n                        \"filename\": script_file.name\n                    }\n                })\n            except Exception as e:\n                print(f\"‚ùå Error processing {script_file.name}: {str(e)}\")\n                continue\n    \n    return all_screenplays\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:27:56.623085Z","iopub.execute_input":"2025-08-08T09:27:56.623912Z","iopub.status.idle":"2025-08-08T09:27:56.635471Z","shell.execute_reply.started":"2025-08-08T09:27:56.623875Z","shell.execute_reply":"2025-08-08T09:27:56.634535Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"\n# ======================\n# 4. MAIN EXECUTION\n# ======================\nif __name__ == \"__main__\":\n    print(\"üöÄ Starting dataset combination and tagging...\")\n\n    cornell_data = load_and_tag_cornell(CORNELL_EMOTION_INPUT)\n    screenplay_data = load_and_tag_screenplays(SCREENPLAY_ROOT_DIR)\n    \n    final_dataset = cornell_data + screenplay_data\n    \n    import random\n    random.shuffle(final_dataset)\n    \n    print(f\"\\nüéâ Successfully combined {len(cornell_data)} Cornell samples and {len(screenplay_data)} screenplay samples.\")\n    print(f\"Total samples in final dataset: {len(final_dataset)}\")\n    \n    try:\n        with open(FINAL_DATA_OUTPUT, 'w', encoding='utf-8') as f:\n            json.dump(final_dataset, f, indent=4)\n        \n        print(f\"\\n‚úÖ Final dataset saved to: {FINAL_DATA_OUTPUT}\")\n        \n    except Exception as e:\n        print(f\"‚ùå Critical error saving final dataset: {str(e)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:27:59.862398Z","iopub.execute_input":"2025-08-08T09:27:59.863107Z","iopub.status.idle":"2025-08-08T09:28:04.690203Z","shell.execute_reply.started":"2025-08-08T09:27:59.863083Z","shell.execute_reply":"2025-08-08T09:28:04.689321Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting dataset combination and tagging...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tagging Cornell data:   0%|          | 0/304403 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5517e61d0ed40918d15c7899be94c2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tagging imsdb scripts:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe5421e48d647a0bd07cd03e8dba1e7"}},"metadata":{}},{"name":"stdout","text":"‚ö†Ô∏è Skipping empty file: The-Truman-Show_clean.txt\n‚ö†Ô∏è Skipping empty file: The-Prestige_clean.txt\n‚ö†Ô∏è Skipping empty file: The-Matrix_clean.txt\n‚ö†Ô∏è Skipping empty file: The-Dark-Knight_clean.txt\n‚ö†Ô∏è Skipping empty file: The-Godfather_clean.txt\n‚ö†Ô∏è Skipping empty file: The-Shawshank-Redemption_clean.txt\n‚ö†Ô∏è Skipping empty file: The-Social-Network_clean.txt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tagging springfield scripts:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceb31d0de4634396a7c55325eeb9c959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tagging screenplaydb scripts: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8482d21b3e64905a42577aa07a975b3"}},"metadata":{}},{"name":"stdout","text":"\nüéâ Successfully combined 304403 Cornell samples and 25 screenplay samples.\nTotal samples in final dataset: 304428\n\n‚úÖ Final dataset saved to: /kaggle/working/data/final_dataset.json\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nimport os\nimport random\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\nfrom datasets import Dataset\nimport torch\n\n# ======================\n# 1. PATH CONFIGURATION\n# ======================\nFINAL_DATA_INPUT = \"/kaggle/working/data/final_dataset.json\"\nMODEL_OUTPUT_DIR = \"/kaggle/working/deepscript-model\"\n\n# --- NEW: Define the path to your checkpoint ---\n# You need to manually update this with the name of your latest checkpoint folder,\n# e.g., \"checkpoint-1234\"\nRESUME_CHECKPOINT_PATH = \"/kaggle/working/deepscript-model/checkpoint-1234\"\n\n# ======================\n# 2. LOAD DATASET (Same as before)\n# ======================\ndef load_and_preprocess_data(file_path):\n    \"\"\"Loads the final dataset and formats it for training.\"\"\"\n    if not Path(file_path).exists():\n        raise FileNotFoundError(f\"‚ùå Final dataset file not found: {file_path}\")\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    processed_data = [{\"text\": item[\"text\"]} for item in data]\n    dataset = Dataset.from_list(processed_data)\n    dataset = dataset.shuffle(seed=42)\n    \n    return dataset\n\n# ======================\n# 3. TOKENIZER SETUP (Same as before, but loads from checkpoint if it exists)\n# ======================\ndef setup_tokenizer(special_tokens, checkpoint_path=None):\n    \"\"\"Loads GPT-2 tokenizer and adds new special tokens, from a checkpoint if specified.\"\"\"\n    if checkpoint_path and Path(checkpoint_path).exists():\n        print(f\"‚úÖ Loading tokenizer from checkpoint: {checkpoint_path}\")\n        tokenizer = GPT2Tokenizer.from_pretrained(checkpoint_path)\n    else:\n        print(\"‚úÖ Loading base GPT-2 tokenizer.\")\n        tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n        tokenizer.add_special_tokens({'additional_special_tokens': list(special_tokens.values())})\n    \n    return tokenizer\n\n# ======================\n# 4. FINE-TUNING EXECUTION\n# ======================\nif __name__ == \"__main__\":\n    print(\"üöÄ Starting GPT-2 fine-tuning process...\")\n    \n    SPECIAL_TOKENS = {\n        \"cornell\": \"<CORNELL_DIALOGUE>\",\n        \"screenplay\": \"<SCREENPLAY>\"\n    }\n\n    # Load and preprocess the dataset\n    try:\n        dataset = load_and_preprocess_data(FINAL_DATA_INPUT)\n    except FileNotFoundError as e:\n        print(e)\n        exit()\n        \n    print(f\"‚úÖ Loaded dataset with {len(dataset)} samples.\")\n    \n    # Setup the tokenizer. It will load from the checkpoint if the path is valid.\n    tokenizer = setup_tokenizer(SPECIAL_TOKENS, RESUME_CHECKPOINT_PATH)\n    \n    # Tokenize the dataset\n    def tokenize_function(examples):\n        return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n        \n    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n    \n    # Split the dataset into training and validation sets\n    train_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n    train_dataset = train_test_split['train']\n    eval_dataset = train_test_split['test']\n    \n    # Load the model. It will load from the checkpoint if the path is valid.\n    if Path(RESUME_CHECKPOINT_PATH).exists():\n        print(f\"‚úÖ Loading model from checkpoint: {RESUME_CHECKPOINT_PATH}\")\n        model = GPT2LMHeadModel.from_pretrained(RESUME_CHECKPOINT_PATH)\n    else:\n        print(\"‚úÖ Loading base GPT-2 model.\")\n        model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n        model.resize_token_embeddings(len(tokenizer))\n    \n    # Define training arguments\n    training_args = TrainingArguments(\n        output_dir=MODEL_OUTPUT_DIR,\n        overwrite_output_dir=True,\n        num_train_epochs=3,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_total_limit=2,\n        logging_dir=f\"{MODEL_OUTPUT_DIR}/logs\",\n        report_to=\"none\"\n    )\n    \n    # Define data collator for language modeling\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n    \n    # Initialize the Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        data_collator=data_collator,\n    )\n    \n    # Start fine-tuning. The trainer will automatically resume if the checkpoint path is provided.\n    print(\"\\n‚è≥ Fine-tuning starting...\")\n    trainer.train(resume_from_checkpoint=RESUME_CHECKPOINT_PATH if Path(RESUME_CHECKPOINT_PATH).exists() else None)\n    \n    # Save the final model and tokenizer\n    trainer.save_model(MODEL_OUTPUT_DIR)\n    tokenizer.save_pretrained(MODEL_OUTPUT_DIR)\n    print(f\"\\n‚úÖ Fine-tuning complete! Model saved to {MODEL_OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:40:46.890032Z","iopub.execute_input":"2025-08-08T09:40:46.890406Z","iopub.status.idle":"2025-08-08T12:35:55.711401Z","shell.execute_reply.started":"2025-08-08T09:40:46.890384Z","shell.execute_reply":"2025-08-08T12:35:55.710587Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting GPT-2 fine-tuning process...\n‚úÖ Loaded dataset with 304428 samples.\n‚úÖ Loading base GPT-2 tokenizer.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/304428 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dc005ddb4434d49959da29b7d91d3f0"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Loading base GPT-2 model.\n\n‚è≥ Fine-tuning starting...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='51375' max='51375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [51375/51375 2:54:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.621600</td>\n      <td>3.280177</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.543200</td>\n      <td>3.233025</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.491000</td>\n      <td>3.212726</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Fine-tuning complete! Model saved to /kaggle/working/deepscript-model\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\n\n# ======================\n# ZIP THE FINAL MODEL\n# ======================\nMODEL_OUTPUT_DIR = \"/kaggle/working/deepscript-model\"\nZIP_FILE_PATH = \"/kaggle/working/deepscript-model.zip\"\n\ndef zip_directory(path, zip_name):\n    \"\"\"\n    Zips a directory and all its contents.\n    \n    Args:\n        path (str): The path to the directory to zip.\n        zip_name (str): The name of the output zip file.\n    \"\"\"\n    if not Path(path).exists():\n        print(f\"‚ùå Model directory not found at: {path}. Skipping zip creation.\")\n        return\n\n    print(f\"‚è≥ Zipping model and tokenizer to {zip_name}...\")\n    try:\n        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for root, _, files in os.walk(path):\n                for file in files:\n                    file_path = os.path.join(root, file)\n                    # Add file to the zip, preserving directory structure\n                    zipf.write(file_path, os.path.relpath(file_path, path))\n        print(f\"‚úÖ Successfully created {zip_name}.\")\n    except Exception as e:\n        print(f\"‚ùå Error creating zip file: {str(e)}\")\n\nif __name__ == \"__main__\":\n    zip_directory(MODEL_OUTPUT_DIR, ZIP_FILE_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:39:30.092702Z","iopub.execute_input":"2025-08-08T12:39:30.093202Z","iopub.status.idle":"2025-08-08T12:42:18.676389Z","shell.execute_reply.started":"2025-08-08T12:39:30.093179Z","shell.execute_reply":"2025-08-08T12:42:18.675598Z"}},"outputs":[{"name":"stdout","text":"‚è≥ Zipping model and tokenizer to /kaggle/working/deepscript-model.zip...\n‚úÖ Successfully created /kaggle/working/deepscript-model.zip.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# ======================\n# 1. PATH CONFIGURATION\n# ======================\nMODEL_OUTPUT_DIR = \"/kaggle/working/deepscript-model\"\n\n# ======================\n# 2. LOAD MODEL AND TOKENIZER\n# ======================\nprint(\"‚è≥ Loading fine-tuned model and tokenizer...\")\ntry:\n    finetuned_tokenizer = GPT2Tokenizer.from_pretrained(MODEL_OUTPUT_DIR)\n    finetuned_model = GPT2LMHeadModel.from_pretrained(MODEL_OUTPUT_DIR)\n    finetuned_model.to('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"‚úÖ Model and tokenizer loaded successfully.\")\nexcept Exception as e:\n    print(f\"‚ùå Error loading model: {str(e)}\")\n    print(\"Please ensure your fine-tuning script has run and saved the model to the correct directory.\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:49:18.791508Z","iopub.execute_input":"2025-08-08T12:49:18.792081Z","iopub.status.idle":"2025-08-08T12:49:19.115330Z","shell.execute_reply.started":"2025-08-08T12:49:18.792061Z","shell.execute_reply":"2025-08-08T12:49:19.114570Z"}},"outputs":[{"name":"stdout","text":"‚è≥ Loading fine-tuned model and tokenizer...\n‚úÖ Model and tokenizer loaded successfully.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"\n# ======================\n# 3. GENERATE TEXT\n# ======================\ndef generate_text_with_prompt(model, tokenizer, prompt, max_length=100):\n    \"\"\"\n    Generates text from a given prompt using the fine-tuned model.\n    \"\"\"\n    print(f\"\\nüìù Generating text for prompt: '{prompt}'\")\n    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(model.device)\n    \n    # These parameters have been adjusted for more coherent output\n    output_tokens = model.generate(\n        input_ids,\n        max_length=max_length,\n        num_return_sequences=1,\n        no_repeat_ngram_size=2,\n        do_sample=True,\n        top_k=50,\n        top_p=0.8,      # Lowered top_p from 0.95 to 0.8\n        temperature=0.6, # Lowered temperature from 0.7 to 0.6\n        pad_token_id=tokenizer.pad_token_id\n    )\n    \n    generated_text = tokenizer.decode(output_tokens[0], skip_special_tokens=False)\n    print(\"\\n--- Generated Output ---\")\n    print(generated_text)\n    print(\"------------------------\")\n    return generated_text\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:49:49.693984Z","iopub.execute_input":"2025-08-08T12:49:49.694266Z","iopub.status.idle":"2025-08-08T12:49:49.699545Z","shell.execute_reply.started":"2025-08-08T12:49:49.694245Z","shell.execute_reply":"2025-08-08T12:49:49.698836Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# ======================\n# 4. RUN GENERATION EXAMPLES\n# ======================\nif __name__ == \"__main__\":\n    # Example 1: Generate a screenplay scene\n    screenplay_prompt = \"<SCREENPLAY> INT. ABANDONED WAREHOUSE - NIGHT\"\n    generate_text_with_prompt(finetuned_model, finetuned_tokenizer, screenplay_prompt)\n    \n    # Example 2: Generate a dialogue with a new prompt\n     # Example 2: Generate a dialogue between two guys\n    dialogue_prompt = \"<CORNELL_DIALOGUE> MARK: Hey man, what's up? \\nJOHN: \"\n    generate_text_with_prompt(finetuned_model, finetuned_tokenizer, dialogue_prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T12:54:38.422775Z","iopub.execute_input":"2025-08-08T12:54:38.423044Z","iopub.status.idle":"2025-08-08T12:54:40.139070Z","shell.execute_reply.started":"2025-08-08T12:54:38.423022Z","shell.execute_reply":"2025-08-08T12:54:40.138331Z"}},"outputs":[{"name":"stdout","text":"\nüìù Generating text for prompt: '<SCREENPLAY> INT. ABANDONED WAREHOUSE - NIGHT'\n\n--- Generated Output ---\n<SCREENPLAY>  INT. ABANDONED WAREHOUSE - NIGHT. The door opens and a young man is standing in the doorway. He looks around, then turns back to the door. A young woman is walking down the hall. She is wearing a black dress. Her hair is in a bun. Behind her is a man. His face is blank. It is very dark. At the end of the hallway is another young MAN. They both look at him. Then they look back at each\n------------------------\n\nüìù Generating text for prompt: '<CORNELL_DIALOGUE> MARK: Hey man, what's up? \nJOHN: '\n\n--- Generated Output ---\n<CORNELL_DIALOGUE>  MARK: Hey man, what's up? \nJOHN:  I'm not getting a job.  And I don't know if I can afford it. I gotta get out of here. There's no way I could afford to. So I'll just have to get some money and get back to my old life. How's that? I mean, I've got a lot of work to do. What's the matter with you? You don¬ít have a car.\n------------------------\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ====================================================================\n# This script fine-tunes a GPT-2 model on a dialogue dataset that has\n# been pre-processed with emotion tags.\n# The goal is to train the model to generate conversations that\n# adhere to a specific format: [EMOTION] SPEAKER: TEXT.\n# ====================================================================\n\nimport json\nimport os\nfrom pathlib import Path\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nfrom datasets import Dataset, load_dataset\nfrom huggingface_hub import login\n\n# ======================\n# 1. AUTHENTICATION & PATHS\n# ======================\n# Your Hugging Face token has been added here.\nlogin(token=\"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\")\n\n# Path to your cleaned and emotion-tagged dataset\nCLEANED_DATASET_PATH = \"/kaggle/working/data/cleaned_cornell.txt\"\n\n# Path where the fine-tuned model will be saved\nOUTPUT_DIR = \"/kaggle/working/emotion-model\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======================\n# 2. DATA PREPARATION & LOADING\n# ======================\ndef load_and_format_dataset(file_path):\n    \"\"\"\n    Loads the JSON data and formats each entry into a single string\n    for fine-tuning the language model.\n    \"\"\"\n    if not Path(file_path).exists():\n        print(f\"‚ùå Error: Dataset file not found at {file_path}\")\n        return None\n\n    print(\"‚è≥ Loading and formatting dataset...\")\n    with open(file_path, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n\n    formatted_texts = []\n    for item in data:\n        character = item['metadata']['character']\n        emotion = item['metadata']['emotion']\n        text = item['text'].split(\": \", 1)[-1]  # Get the text after the character name\n        # Create a single string in the format the model should learn\n        formatted_text = f\"[{emotion.upper()}] {character}: {text}\"\n        formatted_texts.append(formatted_text)\n\n    print(f\"‚úÖ Loaded {len(formatted_texts)} dialogues.\")\n    return formatted_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T13:42:44.667045Z","iopub.execute_input":"2025-08-08T13:42:44.667682Z","iopub.status.idle":"2025-08-08T13:42:44.672669Z","shell.execute_reply.started":"2025-08-08T13:42:44.667662Z","shell.execute_reply":"2025-08-08T13:42:44.672077Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"\n# ======================\n# 3. MODEL AND TOKENIZER SETUP\n# ======================\ndef setup_model_and_tokenizer():\n    \"\"\"\n    Initializes the GPT-2 tokenizer and model for fine-tuning.\n    \"\"\"\n    print(\"‚è≥ Setting up model and tokenizer...\")\n    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n    \n    # Add a new pad token and resize the model's token embeddings\n    # This is crucial for handling variable-length sequences\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))\n    \n    print(\"‚úÖ Model and tokenizer set up successfully.\")\n    return tokenizer, model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T13:42:45.026798Z","iopub.execute_input":"2025-08-08T13:42:45.027021Z","iopub.status.idle":"2025-08-08T13:42:45.031227Z","shell.execute_reply.started":"2025-08-08T13:42:45.027003Z","shell.execute_reply":"2025-08-08T13:42:45.030697Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ======================\n# 4. FINE-TUNING FUNCTION\n# ======================\ndef fine_tune_model():\n    \"\"\"\n    Loads the data, sets up the model, and runs the fine-tuning process.\n    \"\"\"\n    formatted_data = load_and_format_dataset(CLEANED_DATASET_PATH)\n    if not formatted_data:\n        return\n\n    tokenizer, model = setup_model_and_tokenizer()\n\n    # Convert our formatted data into a Hugging Face Dataset\n    dataset = Dataset.from_dict({'text': formatted_data})\n    \n    # Tokenize the dataset\n    def tokenize_function(examples):\n        return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n\n    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n    \n    # Set the `labels` for language modeling\n    tokenized_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask'])\n    \n    # Set labels as input_ids for Causal Language Modeling\n    def set_labels(examples):\n        examples[\"labels\"] = examples[\"input_ids\"].clone()\n        return examples\n\n    tokenized_dataset = tokenized_dataset.map(set_labels, batched=True)\n\n    # --- NEW: SPLIT THE DATASET FOR TRAINING AND VALIDATION ---\n    split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n    train_dataset = split_dataset['train']\n    eval_dataset = split_dataset['test']\n    print(f\"‚úÖ Dataset split: {len(train_dataset)} samples for training, {len(eval_dataset)} for validation.\")\n    \n    # Define training arguments\n    training_args = TrainingArguments(\n        output_dir=OUTPUT_DIR,\n        overwrite_output_dir=True,\n        num_train_epochs=3,  # Adjusted to 3 epochs\n        per_device_train_batch_size=8,\n        save_steps=10_000,\n        save_total_limit=2,\n        prediction_loss_only=True,\n        evaluation_strategy=\"epoch\",  # NEW: Evaluate at the end of each epoch\n    )\n\n    # Initialize the Trainer with both train and evaluation datasets\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset, # NEW: Pass the validation dataset here\n        tokenizer=tokenizer,\n    )\n    \n    print(\"üöÄ Starting fine-tuning...\")\n    # Fine-tune the model\n    trainer.train()\n    print(\"‚úÖ Fine-tuning complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T13:46:56.869103Z","iopub.execute_input":"2025-08-08T13:46:56.869420Z","iopub.status.idle":"2025-08-08T13:46:56.877426Z","shell.execute_reply.started":"2025-08-08T13:46:56.869396Z","shell.execute_reply":"2025-08-08T13:46:56.876655Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"print(\"üöÄ Starting fine-tuning...\")\n    # Fine-tune the model\ntrainer.train()\nprint(\"‚úÖ Fine-tuning complete.\")\n    \n    # Save the final model and tokenizer\ntrainer.save_model(OUTPUT_DIR)\nprint(f\"\\n‚ú® Final model saved to {OUTPUT_DIR}\")\n    \n# ======================\n# 5. EXECUTION\n# ======================\nif __name__ == \"__main__\":\n    fine_tune_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T13:46:58.455692Z","iopub.execute_input":"2025-08-08T13:46:58.456405Z","iopub.status.idle":"2025-08-08T16:42:50.223591Z","shell.execute_reply.started":"2025-08-08T13:46:58.456379Z","shell.execute_reply":"2025-08-08T16:42:50.222326Z"}},"outputs":[{"name":"stdout","text":"üöÄ Starting fine-tuning...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='51375' max='51375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [51375/51375 2:54:36, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.535800</td>\n      <td>3.254994</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.478600</td>\n      <td>3.225784</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.438100</td>\n      <td>3.215687</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Fine-tuning complete.\n\n‚ú® Final model saved to /kaggle/working/emotion-model\n‚è≥ Loading and formatting dataset...\n‚úÖ Loaded 304403 dialogues.\n‚è≥ Setting up model and tokenizer...\n‚úÖ Model and tokenizer set up successfully.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/304403 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ded5851ba24847f39a0f9e9271c717b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/304403 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e724f0d3cc4344ed8361f85ee3b14679"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Dataset split: 273962 samples for training, 30441 for validation.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3080665186.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ======================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfine_tune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3485877411.py\u001b[0m in \u001b[0;36mfine_tune_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Define training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moverwrite_output_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"],"ename":"TypeError","evalue":"TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'","output_type":"error"}],"execution_count":90},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport os\nimport random\nimport re\n\n# Configuration\nMODEL_DIR = \"/kaggle/working/emotion-model\"\nMAX_HISTORY = 3\nINTERRUPTION_CHANCE = 0.15\n\n# Enhanced emotion system with better transitions\nEMOTIONS = {\n    'neutral': ['happy', 'curious', 'confused'],\n    'happy': ['excited', 'neutral', 'amused'],\n    'angry': ['annoyed', 'frustrated', 'neutral'],\n    'confused': ['realization', 'frustration', 'neutral'],\n    'excited': ['happy', 'enthusiastic', 'neutral'],\n    'annoyed': ['angry', 'frustrated', 'neutral'],\n    'realization': ['happy', 'neutral', 'surprised']\n}\n\nclass ShoppingDialogue:\n    def __init__(self):\n        self.speakers = [\"Aadarsha\", \"Aaditya\", \"Bishwa\"]\n        self.scene = \"Three boys went shopping at the mall\"\n        self.history = []\n        self.current_emotions = {speaker: 'neutral' for speaker in self.speakers}\n        \n    def run(self):\n        print(f\"\\n=== SCENE ===\\n{self.scene}\\n\")\n        print(\"=== CONVERSATION ===\")\n        \n        current_speaker = random.choice(self.speakers)\n        for _ in range(8):  # 8 turns as requested\n            # Generate appropriate dialogue\n            dialogue = self.generate_dialogue(current_speaker)\n            self.history.append(dialogue)\n            print(f\"[{self.current_emotions[current_speaker]}] {current_speaker}: {dialogue}\")\n            \n            # Update emotion naturally\n            self.update_emotion(current_speaker, dialogue)\n            \n            # Handle interruptions\n            if random.random() < INTERRUPTION_CHANCE:\n                interrupter = random.choice([s for s in self.speakers if s != current_speaker])\n                print(f\"{interrupter}: [interrupting]\")\n                current_speaker = interrupter\n            else:\n                current_speaker = random.choice([s for s in self.speakers if s != current_speaker])\n\n    def generate_dialogue(self, speaker):\n        \"\"\"Generate context-appropriate shopping dialogue\"\"\"\n        topics = [\n            \"looking at shirts\", \n            \"checking out shoes\",\n            \"trying on jeans\",\n            \"comparing prices\",\n            \"deciding what to buy\",\n            \"looking for deals\",\n            \"discussing brands\",\n            \"choosing colors\"\n        ]\n        templates = [\n            f\"What do you think of these {random.choice(topics)}?\",\n            f\"I really like this {random.choice(['shirt', 'jacket', 'pair of shoes'])}.\",\n            f\"Should we check out the {random.choice(['sale section', 'new arrivals', 'accessories'])}?\",\n            f\"This {random.choice(['store', 'brand', 'section'])} has good options.\",\n            f\"Let's go look at {random.choice(['the other floor', 'another store', 'the food court'])} after this.\"\n        ]\n        \n        # Ensure dialogue stays on shopping topic\n        return random.choice(templates)\n\n    def update_emotion(self, speaker, dialogue):\n        \"\"\"Update emotion based on dialogue content\"\"\"\n        current = self.current_emotions[speaker]\n        \n        # Simple emotion progression\n        if '?' in dialogue:\n            self.current_emotions[speaker] = 'confused' if random.random() < 0.5 else 'curious'\n        elif '!' in dialogue:\n            self.current_emotions[speaker] = 'excited'\n        elif any(word in dialogue.lower() for word in ['like', 'love', 'great']):\n            self.current_emotions[speaker] = 'happy'\n        elif any(word in dialogue.lower() for word in ['hate', 'annoying', 'bad']):\n            self.current_emotions[speaker] = 'angry'\n        else:\n            # Normal transition\n            self.current_emotions[speaker] = random.choice(EMOTIONS[current])\n\nif __name__ == \"__main__\":\n    # Load model\n    if not os.path.exists(MODEL_DIR):\n        print(f\"Error: Model not found at {MODEL_DIR}\")\n    else:\n        tokenizer = GPT2Tokenizer.from_pretrained(MODEL_DIR)\n        model = GPT2LMHeadModel.from_pretrained(MODEL_DIR)\n        dialogue = ShoppingDialogue()\n        dialogue.run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T18:49:25.377656Z","iopub.execute_input":"2025-08-08T18:49:25.378216Z","iopub.status.idle":"2025-08-08T18:49:25.528414Z","shell.execute_reply.started":"2025-08-08T18:49:25.378194Z","shell.execute_reply":"2025-08-08T18:49:25.527767Z"}},"outputs":[{"name":"stdout","text":"\n=== SCENE ===\nThree boys went shopping at the mall\n\n=== CONVERSATION ===\n[neutral] Bishwa: What do you think of these choosing colors?\n[neutral] Aadarsha: This section has good options.\nBishwa: [interrupting]\n[confused] Bishwa: What do you think of these looking at shirts?\n[neutral] Aaditya: What do you think of these trying on jeans?\n[confused] Bishwa: This section has good options.\n[happy] Aadarsha: I really like this jacket.\nAaditya: [interrupting]\n[confused] Aaditya: Should we check out the new arrivals?\n[realization] Bishwa: Should we check out the new arrivals?\n","output_type":"stream"}],"execution_count":125},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport os\nimport random\nimport re\nfrom typing import List, Dict, Tuple\n\n# Configuration\nMODEL_DIR = \"/kaggle/working/emotion-model\"\nMAX_HISTORY = 3\nINTERRUPTION_CHANCE = 0.15\n\n# Complete 28 emotions with detailed transitions\nEMOTIONS = {\n    'admiration': {\n        'transitions': ['approval', 'gratitude', 'neutral'],\n        'trigger_words': ['impressed', 'wow', 'amazing']\n    },\n    'amusement': {\n        'transitions': ['joy', 'excitement', 'neutral'],\n        'trigger_words': ['laugh', 'funny', 'hilarious']\n    },\n    'anger': {\n        'transitions': ['annoyance', 'frustration', 'rage'],\n        'trigger_words': ['angry', 'mad', 'furious']\n    },\n    'annoyance': {\n        'transitions': ['irritation', 'frustration', 'neutral'],\n        'trigger_words': ['annoying', 'bother', 'ugh']\n    },\n    'approval': {\n        'transitions': ['admiration', 'gratitude', 'neutral'],\n        'trigger_words': ['agree', 'support', 'yes']\n    },\n    'caring': {\n        'transitions': ['love', 'gratitude', 'neutral'],\n        'trigger_words': ['care', 'concern', 'worry']\n    },\n    'confusion': {\n        'transitions': ['curiosity', 'realization', 'neutral'],\n        'trigger_words': ['confused', 'dont understand', 'what']\n    },\n    'curiosity': {\n        'transitions': ['confusion', 'excitement', 'neutral'],\n        'trigger_words': ['wonder', 'ask', 'question']\n    },\n    'desire': {\n        'transitions': ['excitement', 'anticipation', 'neutral'],\n        'trigger_words': ['want', 'wish', 'desire']\n    },\n    'disappointment': {\n        'transitions': ['sadness', 'regret', 'neutral'],\n        'trigger_words': ['let down', 'disappointed', 'unhappy']\n    },\n    'disapproval': {\n        'transitions': ['anger', 'annoyance', 'neutral'],\n        'trigger_words': ['disagree', 'against', 'no']\n    },\n    'disgust': {\n        'transitions': ['contempt', 'anger', 'neutral'],\n        'trigger_words': ['gross', 'disgusting', 'ew']\n    },\n    'embarrassment': {\n        'transitions': ['shame', 'regret', 'neutral'],\n        'trigger_words': ['embarrassed', 'awkward', 'cringe']\n    },\n    'excitement': {\n        'transitions': ['joy', 'anticipation', 'neutral'],\n        'trigger_words': ['excited', 'thrilled', 'can\\'t wait']\n    },\n    'fear': {\n        'transitions': ['anxiety', 'nervousness', 'neutral'],\n        'trigger_words': ['scared', 'afraid', 'fear']\n    },\n    'gratitude': {\n        'transitions': ['approval', 'admiration', 'neutral'],\n        'trigger_words': ['thank', 'appreciate', 'grateful']\n    },\n    'grief': {\n        'transitions': ['sadness', 'despair', 'neutral'],\n        'trigger_words': ['loss', 'mourn', 'heartbroken']\n    },\n    'joy': {\n        'transitions': ['amusement', 'excitement', 'neutral'],\n        'trigger_words': ['happy', 'joyful', 'delighted']\n    },\n    'love': {\n        'transitions': ['caring', 'admiration', 'neutral'],\n        'trigger_words': ['love', 'adore', 'cherish']\n    },\n    'nervousness': {\n        'transitions': ['fear', 'anxiety', 'neutral'],\n        'trigger_words': ['nervous', 'anxious', 'worried']\n    },\n    'optimism': {\n        'transitions': ['hope', 'excitement', 'neutral'],\n        'trigger_words': ['optimistic', 'hopeful', 'positive']\n    },\n    'pride': {\n        'transitions': ['confidence', 'satisfaction', 'neutral'],\n        'trigger_words': ['proud', 'accomplished', 'achievement']\n    },\n    'realization': {\n        'transitions': ['surprise', 'understanding', 'neutral'],\n        'trigger_words': ['realize', 'understand', 'oh']\n    },\n    'relief': {\n        'transitions': ['gratitude', 'contentment', 'neutral'],\n        'trigger_words': ['relieved', 'thankful', 'phew']\n    },\n    'remorse': {\n        'transitions': ['regret', 'guilt', 'neutral'],\n        'trigger_words': ['sorry', 'apologize', 'regret']\n    },\n    'sadness': {\n        'transitions': ['grief', 'loneliness', 'neutral'],\n        'trigger_words': ['sad', 'upset', 'depressed']\n    },\n    'surprise': {\n        'transitions': ['shock', 'amazement', 'neutral'],\n        'trigger_words': ['surprised', 'wow', 'shocked']\n    },\n    'neutral': {\n        'transitions': ['curiosity', 'interest', 'contentment'],\n        'trigger_words': []\n    }\n}\n\nclass DeepScriptDialogue:\n    def __init__(self):\n        self.speakers = []\n        self.scene = \"\"\n        self.history = []\n        self.states = {}\n        self.tokenizer = None\n        self.model = None\n\n    def initialize(self):\n        \"\"\"Initialize the complete dialogue system\"\"\"\n        self._load_model()\n        self._get_speakers()\n        self._get_scene()\n        self._initialize_states()\n        self._start_conversation()\n\n    def _load_model(self):\n        \"\"\"Load the GPT-2 model and tokenizer\"\"\"\n        if not os.path.exists(MODEL_DIR):\n            raise FileNotFoundError(f\"Model not found at {MODEL_DIR}\")\n        \n        self.tokenizer = GPT2Tokenizer.from_pretrained(MODEL_DIR)\n        self.model = GPT2LMHeadModel.from_pretrained(MODEL_DIR)\n        print(\"Model loaded successfully\")\n\n    def _get_speakers(self):\n        \"\"\"Get speaker information from user\"\"\"\n        print(\"\\n=== SPEAKER SETUP ===\")\n        \n        # Get number of speakers\n        while True:\n            try:\n                num_speakers = int(input(\"Enter number of speakers (2-6): \"))\n                if 2 <= num_speakers <= 6:\n                    break\n                print(\"Please enter between 2 and 6 speakers\")\n            except ValueError:\n                print(\"Please enter a valid number\")\n\n        # Get each speaker's name\n        self.speakers = []\n        for i in range(1, num_speakers + 1):\n            while True:\n                name = input(f\"Enter name for speaker {i}: \").strip()\n                if name:\n                    self.speakers.append(name)\n                    break\n                print(\"Name cannot be empty\")\n\n    def _get_scene(self):\n        \"\"\"Get scene description from user\"\"\"\n        print(\"\\n=== SCENE SETUP ===\")\n        while True:\n            self.scene = input(\"Enter scene description: \").strip()\n            if self.scene:\n                break\n            print(\"Scene description cannot be empty\")\n\n    def _initialize_states(self):\n        \"\"\"Initialize emotional states for each speaker\"\"\"\n        self.states = {}\n        initial_emotion = self._determine_initial_emotion()\n        \n        for speaker in self.speakers:\n            self.states[speaker] = {\n                'emotion': initial_emotion,\n                'history': [],\n                'interruptions': 0\n            }\n\n    def _determine_initial_emotion(self) -> str:\n        \"\"\"Determine initial emotion based on scene context\"\"\"\n        scene_lower = self.scene.lower()\n        \n        if any(word in scene_lower for word in ['argue', 'fight', 'conflict']):\n            return 'anger'\n        elif any(word in scene_lower for word in ['happy', 'celebrate', 'joy']):\n            return 'joy'\n        elif any(word in scene_lower for word in ['sad', 'grief', 'loss']):\n            return 'sadness'\n        elif any(word in scene_lower for word in ['discuss', 'talk', 'meet']):\n            return 'neutral'\n        else:\n            return 'neutral'\n\n    def _start_conversation(self):\n        \"\"\"Begin the dialogue generation\"\"\"\n        print(\"\\n=== CONVERSATION START ===\")\n        \n        # Get number of turns\n        while True:\n            try:\n                turns = int(input(\"Enter number of dialogue turns (3-20): \"))\n                if 3 <= turns <= 20:\n                    break\n                print(\"Please enter between 3 and 20 turns\")\n            except ValueError:\n                print(\"Please enter a valid number\")\n\n        # Start with random speaker\n        current_speaker = random.choice(self.speakers)\n        \n        for _ in range(turns):\n            # Check for interruption\n            if random.random() < INTERRUPTION_CHANCE and len(self.speakers) > 1:\n                interrupter = random.choice([s for s in self.speakers if s != current_speaker])\n                self._handle_interruption(current_speaker, interrupter)\n                current_speaker = interrupter\n                continue\n            \n            # Generate dialogue\n            dialogue = self._generate_dialogue(current_speaker)\n            self._update_history(current_speaker, dialogue)\n            \n            # Update emotion state\n            self._update_emotion(current_speaker, dialogue)\n            \n            # Print output\n            print(f\"[{self.states[current_speaker]['emotion']}] {current_speaker}: {dialogue}\")\n            \n            # Switch speaker\n            current_speaker = random.choice([s for s in self.speakers if s != current_speaker])\n\n        self._print_final_conversation()\n\n    def _generate_dialogue(self, speaker: str) -> str:\n        \"\"\"Generate dialogue for given speaker\"\"\"\n        prompt = self._build_prompt(speaker)\n        inputs = self.tokenizer.encode(prompt, return_tensors='pt')\n        \n        outputs = self.model.generate(\n            inputs,\n            max_length=len(inputs[0]) + 50,\n            temperature=0.7,\n            top_k=50,\n            top_p=0.9,\n            do_sample=True,\n            pad_token_id=self.tokenizer.eos_token_id,\n            no_repeat_ngram_size=2\n        )\n        \n        generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return self._clean_text(generated[len(prompt):])\n\n    def _build_prompt(self, speaker: str) -> str:\n        \"\"\"Build the context prompt for generation\"\"\"\n        prompt_parts = [\n            f\"Scene: {self.scene}\",\n            \"Current conversation:\",\n            *self.history[-MAX_HISTORY:],\n            f\"Current emotion: {self.states[speaker]['emotion']}\",\n            f\"{speaker}:\"\n        ]\n        return \"\\n\".join(prompt_parts)\n\n    def _clean_text(self, text: str) -> str:\n        \"\"\"Clean and format generated text\"\"\"\n        text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n        text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\']', '', text)  # Remove special chars\n        text = text.strip()\n        \n        # Ensure proper sentence ending\n        if not any(text.endswith(p) for p in ('.', '?', '!', '\"', \"'\")):\n            text += '.'\n        \n        return text[:500]  # Limit length\n\n    def _update_history(self, speaker: str, dialogue: str):\n        \"\"\"Update conversation history\"\"\"\n        entry = f\"[{self.states[speaker]['emotion']}] {speaker}: {dialogue}\"\n        self.history.append(entry)\n        self.states[speaker]['history'].append(entry)\n\n    def _update_emotion(self, speaker: str, dialogue: str):\n        \"\"\"Update speaker's emotional state based on context\"\"\"\n        current_emotion = self.states[speaker]['emotion']\n        \n        # Check for emotion triggers in dialogue\n        for emotion, data in EMOTIONS.items():\n            if any(trigger in dialogue.lower() for trigger in data['trigger_words']):\n                self.states[speaker]['emotion'] = emotion\n                return\n        \n        # If no triggers found, use normal transition\n        possible_transitions = EMOTIONS[current_emotion]['transitions']\n        self.states[speaker]['emotion'] = random.choice(possible_transitions)\n\n    def _handle_interruption(self, current_speaker: str, interrupter: str):\n        \"\"\"Handle conversation interruption\"\"\"\n        interruption_text = f\"{interrupter}: [interrupting]\"\n        self.history.append(interruption_text)\n        self.states[interrupter]['interruptions'] += 1\n        print(interruption_text)\n\n    def _print_final_conversation(self):\n        \"\"\"Print the complete conversation\"\"\"\n        print(\"\\n=== FINAL CONVERSATION ===\")\n        for line in self.history:\n            print(line)\n\nif __name__ == \"__main__\":\n    dialogue_system = DeepScriptDialogue()\n    dialogue_system.initialize()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T18:42:32.184817Z","iopub.execute_input":"2025-08-08T18:42:32.185326Z","iopub.status.idle":"2025-08-08T18:43:25.378229Z","shell.execute_reply.started":"2025-08-08T18:42:32.185297Z","shell.execute_reply":"2025-08-08T18:43:25.377562Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully\n\n=== SPEAKER SETUP ===\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter number of speakers (2-6):  4\nEnter name for speaker 1:  aadarsha\nEnter name for speaker 2:  aaditya\nEnter name for speaker 3:  bishwa\nEnter name for speaker 4:  jagdish\n"},{"name":"stdout","text":"\n=== SCENE SETUP ===\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter scene description:  boys went for shopping\n"},{"name":"stdout","text":"\n=== CONVERSATION START ===\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter number of dialogue turns (3-20):  8\n"},{"name":"stdout","text":"[confusion] aaditya: You're not a man, are you? And what is this man's name? He's a real man. What's his name, Mr. C.? My name is Mr Rothstein. Mr C is the guy I.\n[disapproval] aadarsha: That's not neutral. It's neutral, is it not? It is neutral! Now, why are we here? Because we're here, because we are here! It was neutral ! It can't be neutral now. Now listen, I know.\n[confusion] bishwa: I'll get it back to you. Your name. Your friend. You know what you're doing. Aadasha. But I'm not interested in it. I want to talk to your friends. They're all here. We're.\n[disapproval] aaditya: It'll be a good day. There's nothing here but confusion.     You were the one who told me you were here to see the movie. You can be here tonight. If you.\nbishwa: [interrupting]\n[disapproval] bishwa: You were in the theater.  You are now. Because you are not. It's a film. This is not a movie, it's not even a picture. A film, by the way, a television show.\naaditya: [interrupting]\n[annoyance] aaditya: interrupted  interrupted     interrupt       to the point where the subject is aware of the existence of an intentionality.\n\n=== FINAL CONVERSATION ===\n[neutral] aaditya: You're not a man, are you? And what is this man's name? He's a real man. What's his name, Mr. C.? My name is Mr Rothstein. Mr C is the guy I.\n[neutral] aadarsha: That's not neutral. It's neutral, is it not? It is neutral! Now, why are we here? Because we're here, because we are here! It was neutral ! It can't be neutral now. Now listen, I know.\n[neutral] bishwa: I'll get it back to you. Your name. Your friend. You know what you're doing. Aadasha. But I'm not interested in it. I want to talk to your friends. They're all here. We're.\n[confusion] aaditya: It'll be a good day. There's nothing here but confusion.     You were the one who told me you were here to see the movie. You can be here tonight. If you.\nbishwa: [interrupting]\n[confusion] bishwa: You were in the theater.  You are now. Because you are not. It's a film. This is not a movie, it's not even a picture. A film, by the way, a television show.\naaditya: [interrupting]\n[disapproval] aaditya: interrupted  interrupted     interrupt       to the point where the subject is aware of the existence of an intentionality.\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}